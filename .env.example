# LinkedIn Credentials (only needed if cookies expire - leave empty normally)
LINKEDIN_EMAIL=your-email@example.com
LINKEDIN_PASSWORD=your-password

# Data source: "database" or "csv"
DATA_SOURCE=csv
INPUT_CSV=engineering_graduates.csv
CONNECTIONS_CSV=connections.csv
OUTPUT_CSV=UNT_Alumni_Data.csv
RESULTS_PER_SEARCH=15

# Scraper Settings
USE_COOKIES=true
LINKEDIN_COOKIES_PATH=linkedin_cookies.json
HEADLESS=false
RATE_LIMIT_SECONDS=2
SCROLL_PAUSE_TIME=2
# SCRAPER_MODE = names | search | connections | review
# names: use INPUT_CSV
# search: crawl UNT alumni results pages (supports resume checkpointing)
# connections: use CONNECTIONS_CSV
# review: re-scrape URLs from scraper/output/flagged_for_review.txt
SCRAPER_MODE=search
SCRAPE_RESUME_MAX_AGE_DAYS=7
UPDATE_FREQUENCY=6 months

# Groq AI extraction (optional)
USE_GROQ=true
GROQ_MODEL=llama-3.1-8b-instant
GROQ_API_KEY=
SCRAPER_DEBUG_HTML=false

# LinkedIn Login (for website)
LINKEDIN_CLIENT_ID=your-client-id
LINKEDIN_CLIENT_SECRET=your-client-secret
LINKEDIN_REDIRECT_URI=http://127.0.0.1:5000/auth/linkedin/callback

# Flask
SECRET_KEY=your-flask-secret-key

# Database
MYSQLHOST=your-mysql-host
MYSQLUSER=your-mysql-user
MYSQLPASSWORD=your-mysql-password
MYSQL_DATABASE=your-database-name
MYSQLPORT=37157

# SQLite Fallback (for offline/demo mode)
# Set to 1 to enable local SQLite backup when cloud DB is unreachable
USE_SQLITE_FALLBACK=1
# Set to 1 to completely disable database operations (dev mode)
DISABLE_DB=0

# Testing (drops search to 15s-60s per instead of 2mins-10mins per)
TESTING=false

# Flagging Configuration (Review criteria)
FLAG_MISSING_GRAD_YEAR=false
FLAG_MISSING_DEGREE=false
FLAG_MISSING_EXPERIENCE_DATA=true
